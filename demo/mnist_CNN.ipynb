{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()#继承父类初始化\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):#x 1*28*28\n",
    "        x = F.relu(self.conv1(x)) # 20*24*24\n",
    "        x = F.max_pool2d(x, 2, 2) # 20*12*12\n",
    "        x = F.relu(self.conv2(x)) # 50*8*8\n",
    "        x = F.max_pool2d(x, 2, 2) # 50*4*4\n",
    "        x = x.view(-1,4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dmi=1)\n",
    "        return F.log_softmax(x, dim=1) # log probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./mnist_data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data = datasets.MNIST(\"./mnist_data\", train=True, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                           ]))\n",
    "mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    #enumerate 用于将一个可遍历的数据对象作为一个索引序列\n",
    "    for idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        pred = model(data) #benchsize * 10\n",
    "        loss = F.nll_loss(pred, target)#分类的lossfunction\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "           print(\"Train Epoch: {}, iteration: {}, Loss: {}\".format(\n",
    "           epoch, idx, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()#测试模式\n",
    "    total_loss = 0.\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, (data,target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data) #benchsize * 10\n",
    "            #测试集计算总的损失\n",
    "            total_loss += F.nll_loss(output, target, reduction=\"sum\").item()#分类的lossfunction\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "    \n",
    "    total_loss /= len(test_loader.dataset)\n",
    "    acc = correct/len(test_loader.dataset) * 100.\n",
    "    print(\"Test loss: {}, Accuracy: {}\".format(total_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, iteration: 0, Loss: 2.2941701412200928\n",
      "Train Epoch: 0, iteration: 100, Loss: 0.4841163158416748\n",
      "Train Epoch: 0, iteration: 200, Loss: 0.28404948115348816\n",
      "Train Epoch: 0, iteration: 300, Loss: 0.41409358382225037\n",
      "Train Epoch: 0, iteration: 400, Loss: 0.13008913397789001\n",
      "Train Epoch: 0, iteration: 500, Loss: 0.27093514800071716\n",
      "Train Epoch: 0, iteration: 600, Loss: 0.2826293706893921\n",
      "Train Epoch: 0, iteration: 700, Loss: 0.1390560120344162\n",
      "Train Epoch: 0, iteration: 800, Loss: 0.1593220978975296\n",
      "Train Epoch: 0, iteration: 900, Loss: 0.1107160747051239\n",
      "Train Epoch: 0, iteration: 1000, Loss: 0.08384168148040771\n",
      "Train Epoch: 0, iteration: 1100, Loss: 0.053495556116104126\n",
      "Train Epoch: 0, iteration: 1200, Loss: 0.07284262776374817\n",
      "Train Epoch: 0, iteration: 1300, Loss: 0.012579858303070068\n",
      "Train Epoch: 0, iteration: 1400, Loss: 0.02969057857990265\n",
      "Train Epoch: 0, iteration: 1500, Loss: 0.10437951982021332\n",
      "Train Epoch: 0, iteration: 1600, Loss: 0.019353672862052917\n",
      "Train Epoch: 0, iteration: 1700, Loss: 0.09064418077468872\n",
      "Train Epoch: 0, iteration: 1800, Loss: 0.1630484014749527\n",
      "Test loss: 0.06691024069786072, Accuracy: 97.89\n",
      "Train Epoch: 1, iteration: 0, Loss: 0.03166617453098297\n",
      "Train Epoch: 1, iteration: 100, Loss: 0.007200166583061218\n",
      "Train Epoch: 1, iteration: 200, Loss: 0.006031915545463562\n",
      "Train Epoch: 1, iteration: 300, Loss: 0.023240387439727783\n",
      "Train Epoch: 1, iteration: 400, Loss: 0.07550422847270966\n",
      "Train Epoch: 1, iteration: 500, Loss: 0.010305076837539673\n",
      "Train Epoch: 1, iteration: 600, Loss: 0.00958387553691864\n",
      "Train Epoch: 1, iteration: 700, Loss: 0.03151056170463562\n",
      "Train Epoch: 1, iteration: 800, Loss: 0.016813203692436218\n",
      "Train Epoch: 1, iteration: 900, Loss: 0.014389052987098694\n",
      "Train Epoch: 1, iteration: 1000, Loss: 0.005438700318336487\n",
      "Train Epoch: 1, iteration: 1100, Loss: 0.033480554819107056\n",
      "Train Epoch: 1, iteration: 1200, Loss: 0.02320249378681183\n",
      "Train Epoch: 1, iteration: 1300, Loss: 0.08409803360700607\n",
      "Train Epoch: 1, iteration: 1400, Loss: 0.04208792746067047\n",
      "Train Epoch: 1, iteration: 1500, Loss: 0.1887393593788147\n",
      "Train Epoch: 1, iteration: 1600, Loss: 0.10308537632226944\n",
      "Train Epoch: 1, iteration: 1700, Loss: 0.03325606882572174\n",
      "Train Epoch: 1, iteration: 1800, Loss: 0.027363896369934082\n",
      "Test loss: 0.048231400990486145, Accuracy: 98.52\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "      datasets.MNIST(\"./mnist_data\", train=True, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               #Normalize 减去均值和方差\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])),\n",
    "      batch_size=batch_size, shuffle=True,\n",
    "      num_workers=1, pin_memory=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "      datasets.MNIST(\"./mnist_data\", train=False, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               #Normalize 减去均值和方差\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])),\n",
    "      batch_size=batch_size, shuffle=True,\n",
    "      num_workers=1, pin_memory=True\n",
    ")\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    test(model, device, test_dataloader)\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
